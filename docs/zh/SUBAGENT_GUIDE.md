# Subagent AI Orchestration Guide

## æ¦‚è¿°

Subagent æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ AI ç¼–æ’å·¥å…·æ¨¡å—ï¼Œå…è®¸æ‚¨åœ¨ MCP æœåŠ¡å™¨ä¸­å§”æ´¾å­ä»»åŠ¡ç»™å¤–éƒ¨ AI æ¨¡å‹ï¼ˆOpenAI å’Œ Anthropicï¼‰ã€‚æ”¯æŒå¹¶è¡Œä»»åŠ¡æ‰§è¡Œã€æ¡ä»¶åˆ†æ”¯å†³ç­–ã€token ä½¿ç”¨ç»Ÿè®¡å’Œè‡ªå®šä¹‰æ¨¡å‹ã€‚

## æ ¸å¿ƒåŠŸèƒ½

- âœ… **å¤š AI æ¥å…¥å•†æ”¯æŒ**ï¼šOpenAI (GPT-3.5/4)ã€Anthropic (Claude-3)
- âœ… **è‡ªå®šä¹‰ API ç«¯ç‚¹**ï¼šæ”¯æŒç§æœ‰éƒ¨ç½²å’Œè‡ªå®šä¹‰ API åŸºç¡€ URL
- âœ… **æŒä¹…åŒ–é…ç½®**ï¼šAPI å¯†é’¥è‡ªåŠ¨ä¿å­˜ï¼Œæ— éœ€æ¯æ¬¡é‡æ–°é…ç½®
- âœ… **å¹¶è¡Œä»»åŠ¡æ‰§è¡Œ**ï¼šä½¿ç”¨çº¿ç¨‹æ± åŒæ—¶æ‰§è¡Œå¤šä¸ªç‹¬ç«‹å­ä»»åŠ¡
- âœ… **æ¡ä»¶åˆ†æ”¯å†³ç­–**ï¼šåŸºäº AI åˆ¤æ–­åŠ¨æ€é€‰æ‹©æ‰§è¡Œè·¯å¾„
- âœ… **Token ç»Ÿè®¡**ï¼šå®æ—¶è®¡ç®—è¾“å…¥/è¾“å‡º token ä½¿ç”¨é‡
- âœ… **è‡ªå®šä¹‰æ¨¡å‹æ”¯æŒ**ï¼šæ”¯æŒä½¿ç”¨ä»»æ„è‡ªå®šä¹‰æ¨¡å‹åç§°
- âœ… **æ— çŠ¶æ€è®¾è®¡**ï¼šæ¯æ¬¡è°ƒç”¨ç‹¬ç«‹ï¼Œæ— éœ€ç»´æŠ¤ä¼šè¯çŠ¶æ€
- âœ… **è‡ªåŠ¨é‡è¯•**ï¼šç½‘ç»œå¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•ï¼ˆæœ€å¤š 3 æ¬¡ï¼‰
- âœ… **å®‰å…¨ä¿éšœ**ï¼šAPI å¯†é’¥è‡ªåŠ¨è„±æ•ï¼Œç¯å¢ƒå˜é‡ç®¡ç†

## å¿«é€Ÿå¼€å§‹

### æ–¹å¼ 1: ä½¿ç”¨æŒä¹…åŒ–é…ç½®ï¼ˆæ¨èï¼‰

ä½¿ç”¨é…ç½®ç®¡ç†å·¥å…·æ°¸ä¹…ä¿å­˜ API å¯†é’¥ï¼š

```python
from mcp_server.tools.subagent import subagent_config_set

# è®¾ç½® OpenAI (ä¸€æ¬¡é…ç½®ï¼Œæ°¸ä¹…ç”Ÿæ•ˆ)
subagent_config_set("openai", "sk-proj-xxxxxxxxxxxx")

# è®¾ç½® Anthropic
subagent_config_set("anthropic", "sk-ant-xxxxxxxxxxxx")

# è®¾ç½®è‡ªå®šä¹‰ç«¯ç‚¹
subagent_config_set("openai", "sk-xxx", "https://api.openai-proxy.com/v1")
```

é…ç½®å°†ä¿å­˜åˆ° `~/.subagent_config.json`ï¼Œä¸‹æ¬¡å¯åŠ¨è‡ªåŠ¨åŠ è½½ã€‚

**æŸ¥çœ‹é…ç½®:**

```python
from mcp_server.tools.subagent import subagent_config_list
print(subagent_config_list())
```

ğŸ“š **è¯¦ç»†é…ç½®æ–‡æ¡£**: [Subagent é…ç½®ç®¡ç†æŒ‡å—](./SUBAGENT_CONFIG.md)

### æ–¹å¼ 2: ä½¿ç”¨ç¯å¢ƒå˜é‡

åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®æ‚¨çš„ API å¯†é’¥ï¼ˆä¸´æ—¶ï¼Œæ¯æ¬¡ä¼šè¯æœ‰æ•ˆï¼‰ï¼š

```bash
# OpenAI
export OPENAI_API_KEY="sk-..."

# Anthropic
export ANTHROPIC_API_KEY="sk-ant-..."
```

**Windows PowerShell:**

```powershell
$env:OPENAI_API_KEY = "sk-..."
$env:ANTHROPIC_API_KEY = "sk-ant-..."
```

### 2. è‡ªå®šä¹‰ API ç«¯ç‚¹ï¼ˆå¯é€‰ï¼‰

å¦‚æœæ‚¨ä½¿ç”¨ç§æœ‰éƒ¨ç½²æˆ–è‡ªå®šä¹‰ç«¯ç‚¹ï¼š

```bash
# è‡ªå®šä¹‰ OpenAI ç«¯ç‚¹
export OPENAI_API_BASE="https://your-custom-endpoint.com/v1"

# è‡ªå®šä¹‰ Anthropic ç«¯ç‚¹
export ANTHROPIC_API_BASE="https://your-custom-endpoint.com/v1"
```

### 3. ä½¿ç”¨å·¥å…·

é…ç½®å®Œæˆåï¼ŒMCP æœåŠ¡å™¨ä¼šè‡ªåŠ¨åŠ è½½ Subagent å·¥å…·ã€‚æ‚¨å¯ä»¥åœ¨ Claude Desktop æˆ–ä»»ä½• MCP å®¢æˆ·ç«¯ä¸­ä½¿ç”¨è¿™äº›å·¥å…·ã€‚

## å·¥å…·è¯¦è§£

### 1. `subagent_call` - å•æ¬¡ AI è°ƒç”¨

å§”æ´¾å•ä¸ªå­ä»»åŠ¡ç»™ AI æ¨¡å‹å¤„ç†ã€‚

**å‚æ•°ï¼š**

| å‚æ•°          | ç±»å‹   | å¿…éœ€ | æè¿°                                        |
| ------------- | ------ | ---- | ------------------------------------------- |
| `provider`    | string | âœ“    | AI æä¾›å•†ï¼š`"openai"` æˆ– `"anthropic"`      |
| `model`       | string | âœ“    | æ¨¡å‹åç§°ï¼ˆè§ä¸‹æ–¹æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨ï¼‰            |
| `messages`    | string | âœ“    | JSON æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨                         |
| `max_tokens`  | int    | âœ—    | æœ€å¤§ç”Ÿæˆ token æ•°ï¼ˆé»˜è®¤ï¼šè‡ªåŠ¨ï¼Œä¸Šé™ 32000ï¼‰ |
| `temperature` | float  | âœ—    | æ¸©åº¦å‚æ•° 0.0-2.0ï¼ˆé»˜è®¤ï¼š0.7ï¼‰               |

**è¿”å›ï¼š**

```json
{
  "result": "AI ç”Ÿæˆçš„å“åº”æ–‡æœ¬",
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "model": "gpt-4",
  "provider": "openai",
  "elapsed_time": 2.34,
  "status": "success"
}
```

**ç¤ºä¾‹ï¼š**

```python
# åŸºç¡€ç”¨ä¾‹ï¼šè¯¢é—®é—®é¢˜
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "What is quantum computing?"}
]

result = subagent_call(
    provider="openai",
    model="gpt-3.5-turbo",
    messages=json.dumps(messages),
    max_tokens=500,
    temperature=0.7
)
```

```python
# ä½¿ç”¨ Claude è¿›è¡Œé•¿æ–‡æœ¬å¤„ç†
messages = [
    {"role": "user", "content": "Summarize this document: [long text...]"}
]

result = subagent_call(
    provider="anthropic",
    model="claude-3-5-sonnet-20241022",
    messages=json.dumps(messages),
    max_tokens=4096
)
```

```python
# ä½¿ç”¨ Anthropic Claude å¤„ç†ä¸­æ–‡ä»»åŠ¡
messages = [
    {"role": "user", "content": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½"}
]

result = subagent_call(
    provider="anthropic",
    model="claude-3-5-sonnet-20241022",
    messages=json.dumps(messages),
    max_tokens=500,
    temperature=0.7
)
```

### 2. `subagent_parallel` - å¹¶è¡Œä»»åŠ¡æ‰§è¡Œ

åŒæ—¶æ‰§è¡Œå¤šä¸ªç‹¬ç«‹çš„ AI ä»»åŠ¡ï¼Œé€‚åˆéœ€è¦å¹¶å‘å¤„ç†çš„åœºæ™¯ã€‚

**å‚æ•°ï¼š**

| å‚æ•°          | ç±»å‹   | å¿…éœ€ | æè¿°                           |
| ------------- | ------ | ---- | ------------------------------ |
| `tasks`       | string | âœ“    | JSON æ ¼å¼çš„ä»»åŠ¡åˆ—è¡¨            |
| `max_workers` | int    | âœ—    | æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤ï¼š3ï¼Œä¸Šé™ 10ï¼‰ |

**ä»»åŠ¡æ ¼å¼ï¼š**

```json
[
  {
    "name": "task1",
    "provider": "openai",
    "model": "gpt-3.5-turbo",
    "messages": [{ "role": "user", "content": "..." }],
    "max_tokens": 500,
    "temperature": 0.7
  },
  {
    "name": "task2",
    "provider": "anthropic",
    "model": "claude-3-haiku-20240307",
    "messages": [{ "role": "user", "content": "..." }]
  }
]
```

**è¿”å›ï¼š**

```json
{
  "results": [
    {
      "task_name": "task1",
      "task_index": 0,
      "result": "...",
      "usage": {...},
      "status": "success"
    },
    {
      "task_name": "task2",
      "task_index": 1,
      "result": "...",
      "usage": {...},
      "status": "success"
    }
  ],
  "summary": {
    "total_tasks": 2,
    "successful": 2,
    "failed": 0,
    "total_input_tokens": 234,
    "total_output_tokens": 567,
    "total_tokens": 801,
    "elapsed_time": 3.45
  }
}
```

**ç¤ºä¾‹ï¼š**

```python
# å¹¶è¡Œæ‰§è¡Œå¤šä¸ªç‹¬ç«‹åˆ†æä»»åŠ¡
tasks = [
    {
        "name": "analyze_sentiment",
        "provider": "openai",
        "model": "gpt-3.5-turbo",
        "messages": [{"role": "user", "content": "Analyze sentiment: [text]"}]
    },
    {
        "name": "extract_keywords",
        "provider": "openai",
        "model": "gpt-3.5-turbo",
        "messages": [{"role": "user", "content": "Extract keywords: [text]"}]
    },
    {
        "name": "summarize",
        "provider": "anthropic",
        "model": "claude-3-haiku-20240307",
        "messages": [{"role": "user", "content": "Summarize: [text]"}]
    }
]

result = subagent_parallel(
    tasks=json.dumps(tasks),
    max_workers=3
)

# è®¿é—®å„ä¸ªä»»åŠ¡ç»“æœ
for task_result in result["results"]:
    print(f"{task_result['task_name']}: {task_result['result']}")
```

```python
# å¤šè¯­è¨€ç¿»è¯‘å¹¶è¡Œå¤„ç†
tasks = [
    {
        "name": "to_chinese",
        "provider": "openai",
        "model": "gpt-4",
        "messages": [{"role": "user", "content": "Translate to Chinese: Hello world"}]
    },
    {
        "name": "to_french",
        "provider": "openai",
        "model": "gpt-4",
        "messages": [{"role": "user", "content": "Translate to French: Hello world"}]
    },
    {
        "name": "to_spanish",
        "provider": "openai",
        "model": "gpt-4",
        "messages": [{"role": "user", "content": "Translate to Spanish: Hello world"}]
    }
]

result = subagent_parallel(tasks=json.dumps(tasks), max_workers=3)
```

### 3. `subagent_conditional` - æ¡ä»¶åˆ†æ”¯å†³ç­–

å…ˆè®© AI è¯„ä¼°æ¡ä»¶ï¼Œç„¶åæ ¹æ®ç»“æœæ‰§è¡Œä¸åŒçš„åˆ†æ”¯ä»»åŠ¡ã€‚

**å‚æ•°ï¼š**

| å‚æ•°             | ç±»å‹   | å¿…éœ€ | æè¿°                         |
| ---------------- | ------ | ---- | ---------------------------- |
| `condition_task` | string | âœ“    | ç”¨äºè¯„ä¼°æ¡ä»¶çš„ä»»åŠ¡ï¼ˆJSONï¼‰   |
| `true_task`      | string | âœ“    | æ¡ä»¶ä¸ºçœŸæ—¶æ‰§è¡Œçš„ä»»åŠ¡ï¼ˆJSONï¼‰ |
| `false_task`     | string | âœ“    | æ¡ä»¶ä¸ºå‡æ—¶æ‰§è¡Œçš„ä»»åŠ¡ï¼ˆJSONï¼‰ |

**è¿”å›ï¼š**

```json
{
  "condition_result": {
    "text": "true",
    "evaluated_as": true,
    "usage": {...}
  },
  "branch_taken": "true_branch",
  "final_result": {
    "result": "...",
    "usage": {...},
    "status": "success"
  },
  "total_usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "status": "success"
}
```

**ç¤ºä¾‹ï¼š**

```python
# æ ¹æ®æ–‡æœ¬é•¿åº¦é€‰æ‹©å¤„ç†ç­–ç•¥
condition_task = {
    "provider": "openai",
    "model": "gpt-3.5-turbo",
    "messages": [{
        "role": "user",
        "content": "Is this text longer than 1000 words? [text]. Reply only 'true' or 'false'"
    }],
    "max_tokens": 10,
    "temperature": 0.1
}

true_task = {
    "provider": "anthropic",
    "model": "claude-3-5-sonnet-20241022",
    "messages": [{
        "role": "user",
        "content": "Create a detailed summary with sections: [text]"
    }],
    "max_tokens": 2000
}

false_task = {
    "provider": "openai",
    "model": "gpt-3.5-turbo",
    "messages": [{
        "role": "user",
        "content": "Create a brief summary: [text]"
    }],
    "max_tokens": 500
}

result = subagent_conditional(
    condition_task=json.dumps(condition_task),
    true_task=json.dumps(true_task),
    false_task=json.dumps(false_task)
)

print(f"Condition evaluated as: {result['condition_result']['evaluated_as']}")
print(f"Branch taken: {result['branch_taken']}")
```

### 4. `subagent_config_set` - è®¾ç½®é…ç½®

æŒä¹…åŒ–ä¿å­˜ API å¯†é’¥å’Œç«¯ç‚¹é…ç½®åˆ°é…ç½®æ–‡ä»¶ã€‚

**å‚æ•°ï¼š**

| å‚æ•°       | ç±»å‹   | å¿…éœ€ | æè¿°                                    |
| ---------- | ------ | ---- | ------------------------------------------ |
| `provider` | string | âœ“    | æä¾›å•†ï¼š`"openai"` `"anthropic"` |
| `api_key`  | string | âœ“    | API å¯†é’¥                              |
| `api_base` | string | âœ—    | API åŸºç¡€ URLï¼ˆå¯é€‰ï¼‰                         |

**è¿”å›ï¼š**

```json
{
  "provider": "openai",
  "api_key_set": true,
  "api_key_preview": "sk-proj-...xxxx",
  "api_base": "https://api.openai.com/v1",
  "config_file": "/home/user/.subagent_config.json",
  "status": "success"
}
```

**ç¤ºä¾‹ï¼š**

```python
# è®¾ç½® OpenAI API
subagent_config_set("openai", "sk-proj-xxxxxxxxxxxx")

# è®¾ç½®è‡ªå®šä¹‰ç«¯ç‚¹
subagent_config_set("openai", "sk-xxx", "https://api.openai-proxy.com/v1")

# è®¾ç½® Anthropic
subagent_config_set("anthropic", "sk-ant-xxxxxxxxxxxx")
```

### 5. `subagent_config_get` - æŸ¥è¯¢é…ç½®

è·å–æŒ‡å®šæä¾›å•†çš„é…ç½®ä¿¡æ¯ï¼ˆå¯†é’¥å·²è„±æ•ï¼‰ã€‚

**å‚æ•°ï¼š**

| å‚æ•°       | ç±»å‹   | å¿…éœ€ | æè¿°       |
| ---------- | ------ | ---- | ---------- |
| `provider` | string | âœ“    | æä¾›å•†åç§° |

**è¿”å›ï¼š**

```json
{
  "provider": "openai",
  "configured": true,
  "api_key": "sk-proj-...xxxx",
  "api_base": "https://api.openai.com/v1",
  "source": "config_file",
  "config_file": "/home/user/.subagent_config.json",
  "status": "success"
}
```

**ç¤ºä¾‹ï¼š**

```python
# æŸ¥è¯¢ OpenAI é…ç½®
config = subagent_config_get("openai")
print(f"OpenAI é…ç½®æ¥æº: {config['source']}")
```

### 6. `subagent_config_list` - åˆ—å‡ºæ‰€æœ‰é…ç½®

åˆ—å‡ºæ‰€æœ‰å·²é…ç½®çš„ AI æä¾›å•†åŠå…¶çŠ¶æ€ã€‚

**è¿”å›ï¼š**

```json
{
  "providers": {
    "openai": {
      "api_key": "sk-proj-...xxxx",
      "api_base": "https://api.openai.com/v1",
      "source": "config_file"
    },
    "anthropic": {
      "api_key": "sk-ant-...eQhJ",
      "api_base": "https://api.anthropic.com/v1",
      "source": "environment"
    }
  },
  "total_configured": 2,
  "config_file": "/home/user/.subagent_config.json",
  "status": "success"
}
```

**ç¤ºä¾‹ï¼š**

```python
# åˆ—å‡ºæ‰€æœ‰é…ç½®
providers = subagent_config_list()
print(f"å·²é…ç½® {providers['total_configured']} ä¸ªæä¾›å•†")
```

ğŸ“š **å®Œæ•´é…ç½®ç®¡ç†æ–‡æ¡£**: [Subagent é…ç½®ç®¡ç†æŒ‡å—](./SUBAGENT_CONFIG.md)
print(f"Final result: {result['final_result']['result']}")

````

```python
# æ ¹æ®æƒ…æ„Ÿåˆ†æç»“æœé€‰æ‹©å“åº”æ–¹å¼
condition_task = {
    "provider": "openai",
    "model": "gpt-4",
    "messages": [{
        "role": "user",
        "content": "Is this customer feedback positive? '[feedback]'. Reply only 'true' or 'false'"
    }]
}

true_task = {
    "provider": "openai",
    "model": "gpt-3.5-turbo",
    "messages": [{
        "role": "user",
        "content": "Generate a thank you response for positive feedback: [feedback]"
    }]
}

false_task = {
    "provider": "openai",
    "model": "gpt-4",
    "messages": [{
        "role": "user",
        "content": "Generate an empathetic response and solution for negative feedback: [feedback]"
    }]
}

result = subagent_conditional(
    condition_task=json.dumps(condition_task),
    true_task=json.dumps(true_task),
    false_task=json.dumps(false_task)
)
````

## æ”¯æŒçš„æ¨¡å‹

### OpenAI æ¨¡å‹

| æ¨¡å‹            | è¾“å…¥ä»·æ ¼    | è¾“å‡ºä»·æ ¼   | ä¸Šä¸‹æ–‡çª—å£ | é€‚ç”¨åœºæ™¯             |
| --------------- | ----------- | ---------- | ---------- | -------------------- |
| `gpt-3.5-turbo` | $0.0015/1K  | $0.002/1K  | 16K        | å¿«é€Ÿã€ç»æµçš„é€šç”¨ä»»åŠ¡ |
| `gpt-4`         | $0.03/1K    | $0.06/1K   | 8K         | å¤æ‚æ¨ç†ã€é«˜è´¨é‡è¾“å‡º |
| `gpt-4-turbo`   | $0.01/1K    | $0.03/1K   | 128K       | é•¿æ–‡æœ¬å¤„ç†           |
| `gpt-4o`        | $0.005/1K   | $0.015/1K  | 128K       | æœ€æ–°å¤šæ¨¡æ€æ¨¡å‹       |
| `gpt-4o-mini`   | $0.00015/1K | $0.0006/1K | 128K       | æœ€ç»æµçš„å°å‹æ¨¡å‹     |

### Anthropic Claude æ¨¡å‹

| æ¨¡å‹                         | è¾“å…¥ä»·æ ¼    | è¾“å‡ºä»·æ ¼    | ä¸Šä¸‹æ–‡çª—å£ | é€‚ç”¨åœºæ™¯           |
| ---------------------------- | ----------- | ----------- | ---------- | ------------------ |
| `claude-3-haiku-20240307`    | $0.00025/1K | $0.00125/1K | 200K       | å¿«é€Ÿå“åº”ã€ç®€å•ä»»åŠ¡ |
| `claude-3-5-haiku-20241022`  | $0.001/1K   | $0.005/1K   | 200K       | å‡çº§ç‰ˆ Haiku       |
| `claude-3-sonnet-20240229`   | $0.003/1K   | $0.015/1K   | 200K       | å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬     |
| `claude-3-5-sonnet-20241022` | $0.003/1K   | $0.015/1K   | 200K       | æœ€æ–°æœ€å¼º Claude    |
| `claude-3-opus-20240229`     | $0.015/1K   | $0.075/1K   | 200K       | æœ€é«˜è´¨é‡æ¨ç†       |

> **æ³¨æ„**ï¼šä»·æ ¼å¯èƒ½ä¼šéšæ—¶è°ƒæ•´ï¼Œä»¥å®˜æ–¹æœ€æ–°å®šä»·ä¸ºå‡†ã€‚

## Token è®¡æ•°ç®—æ³•

Subagent ä½¿ç”¨å­—ç¬¦è¿‘ä¼¼ç®—æ³•ä¼°ç®— token æ•°é‡ï¼š

- **è‹±æ–‡æ–‡æœ¬**ï¼šçº¦ 4 ä¸ªå­—ç¬¦ = 1 token
- **ä¸­æ–‡æ–‡æœ¬**ï¼šçº¦ 2 ä¸ªå­—ç¬¦ = 1 token
- **æ¶ˆæ¯å¼€é”€**ï¼šæ¯æ¡æ¶ˆæ¯é¢å¤– 4 tokensï¼ˆrole + åˆ†éš”ç¬¦ï¼‰

**å‡†ç¡®æ€§**ï¼šè¯¯å·®çº¦ Â±10%ï¼Œè¶³å¤Ÿç”¨äºæˆæœ¬é¢„ä¼°ã€‚

**ç¤ºä¾‹**ï¼š

```python
text = "Hello world, this is a test."  # 29 characters
# ä¼°ç®—: 29 / 4 â‰ˆ 7 tokens

text_cn = "ä½ å¥½ä¸–ç•Œï¼Œè¿™æ˜¯æµ‹è¯•ã€‚"  # 10 characters
# ä¼°ç®—: 10 / 2 = 5 tokens
```

å¦‚éœ€ç²¾ç¡® token è®¡æ•°ï¼Œå»ºè®®ä½¿ç”¨ï¼š

- OpenAI: `tiktoken` åº“
- Anthropic: `anthropic-tokenizer` åº“

## æˆæœ¬ä¼˜åŒ–å»ºè®®

### 1. é€‰æ‹©åˆé€‚çš„æ¨¡å‹

- **ç®€å•ä»»åŠ¡**ï¼šä½¿ç”¨ `gpt-3.5-turbo` æˆ– `claude-3-haiku`
- **å¤æ‚æ¨ç†**ï¼šä½¿ç”¨ `gpt-4` æˆ– `claude-3-5-sonnet`
- **é•¿æ–‡æœ¬å¤„ç†**ï¼šä½¿ç”¨ `claude-3-5-sonnet`ï¼ˆ200K ä¸Šä¸‹æ–‡ï¼‰

### 2. è®¾ç½® `max_tokens` é™åˆ¶

```python
# é¿å…ä¸å¿…è¦çš„é•¿è¾“å‡º
result = subagent_call(
    provider="openai",
    model="gpt-4",
    messages=messages,
    max_tokens=500  # é™åˆ¶è¾“å‡ºé•¿åº¦
)
```

### 3. ä½¿ç”¨å¹¶è¡Œä»»åŠ¡æé«˜æ•ˆç‡

```python
# ä¸æ¨èï¼šé¡ºåºæ‰§è¡Œ
result1 = subagent_call(...)
result2 = subagent_call(...)
result3 = subagent_call(...)

# æ¨èï¼šå¹¶è¡Œæ‰§è¡Œ
result = subagent_parallel(tasks=[task1, task2, task3])
```

### 4. æ¡ä»¶åˆ†æ”¯é¿å…å†—ä½™è°ƒç”¨

```python
# åªåœ¨å¿…è¦æ—¶è°ƒç”¨æ˜‚è´µçš„æ¨¡å‹
result = subagent_conditional(
    condition_task={...},  # ç”¨ä¾¿å®œçš„æ¨¡å‹åˆ¤æ–­
    true_task={...},       # ç”¨è´µçš„æ¨¡å‹å¤„ç†
    false_task={...}       # è·³è¿‡æˆ–ç”¨ä¾¿å®œçš„æ¨¡å‹
)
```

### 5. Token ä½¿ç”¨ç›‘æ§

æ‰€æœ‰å·¥å…·éƒ½è¿”å› `usage` å­—æ®µï¼Œå®šæœŸæŸ¥çœ‹ token ä½¿ç”¨æƒ…å†µï¼š

```python
result = subagent_call(...)
print(f"Tokens used: {result['usage']['total_tokens']}")
print(f"Input tokens: {result['usage']['prompt_tokens']}")
print(f"Output tokens: {result['usage']['completion_tokens']}")

result = subagent_parallel(...)
print(f"Total tokens: {result['summary']['total_tokens']}")
print(f"Tasks completed: {result['summary']['successful']}/{result['summary']['total_tasks']}")
```

**æˆæœ¬æŸ¥è¯¢**: å¯ä»¥é€šè¿‡ API provider çš„å®˜æ–¹æ§åˆ¶å°æŸ¥çœ‹å®é™…æˆæœ¬ï¼š
- **OpenAI**: https://platform.openai.com/usage
- **Anthropic**: https://console.anthropic.com/settings/usage

## é”™è¯¯å¤„ç†

### å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ³•

#### 1. API å¯†é’¥æœªè®¾ç½®

**é”™è¯¯**ï¼š`OPENAI_API_KEY environment variable not set`

**è§£å†³**ï¼š

```bash
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="sk-ant-..."
```

#### 2. API å¯†é’¥æ— æ•ˆ

**é”™è¯¯**ï¼š`Invalid OpenAI API key` æˆ– `Invalid Anthropic API key`

**è§£å†³**ï¼šæ£€æŸ¥ API å¯†é’¥æ˜¯å¦æ­£ç¡®ï¼Œæ˜¯å¦å·²è¿‡æœŸã€‚

#### 3. é€Ÿç‡é™åˆ¶

**é”™è¯¯**ï¼š`API rate limit exceeded`

**è§£å†³**ï¼š

- å‡å°‘å¹¶å‘æ•°ï¼š`max_workers=1`
- ç­‰å¾…åé‡è¯•
- å‡çº§ API å¥—é¤

#### 4. è¶…æ—¶

**é”™è¯¯**ï¼š`API timeout after 300s`

**è§£å†³**ï¼š

- å‡å°‘ `max_tokens` ä»¥åŠ å¿«ç”Ÿæˆ
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ï¼ˆå¦‚ `gpt-3.5-turbo`ï¼‰

#### 5. Token è¶…é™

**é”™è¯¯**ï¼š`max_tokens cannot exceed 32000`

**è§£å†³**ï¼š

- å‡å°‘è¾“å…¥æ–‡æœ¬é•¿åº¦
- åˆ†æ‰¹å¤„ç†é•¿æ–‡æœ¬
- ä½¿ç”¨æ”¯æŒæ›´å¤§ä¸Šä¸‹æ–‡çš„æ¨¡å‹

### é‡è¯•æœºåˆ¶

Subagent è‡ªåŠ¨é‡è¯•å¤±è´¥çš„ API è°ƒç”¨ï¼ˆæœ€å¤š 3 æ¬¡ï¼‰ï¼š

- **é‡è¯•æ¬¡æ•°**ï¼š3
- **åˆå§‹å»¶è¿Ÿ**ï¼š1 ç§’
- **é€€é¿ç³»æ•°**ï¼š2.0ï¼ˆæŒ‡æ•°é€€é¿ï¼‰

é‡è¯•åœºæ™¯ï¼š

- ç½‘ç»œè¶…æ—¶
- 503 æœåŠ¡ä¸å¯ç”¨
- ä¸´æ—¶æ€§ç½‘ç»œé”™è¯¯

## å®‰å…¨æ€§

### API å¯†é’¥ä¿æŠ¤

1. **ç¯å¢ƒå˜é‡å­˜å‚¨**ï¼šå¯†é’¥ä¸ç¡¬ç¼–ç åˆ°ä»£ç ä¸­
2. **è‡ªåŠ¨è„±æ•**ï¼šæ—¥å¿—ä¸­çš„ API å¯†é’¥è‡ªåŠ¨éšè—
3. **ä¼ è¾“åŠ å¯†**ï¼šæ‰€æœ‰ API è°ƒç”¨ä½¿ç”¨ HTTPS

### æ•æ„Ÿè¯è¿‡æ»¤

ä»¥ä¸‹å…³é”®è¯åœ¨æ—¥å¿—ä¸­è‡ªåŠ¨è„±æ•ï¼š

- `PASSWORD`
- `SECRET`
- `TOKEN`
- `KEY`
- `CREDENTIAL`
- `API_KEY`

### è¾“å…¥éªŒè¯

- **æ¶ˆæ¯æ ¼å¼éªŒè¯**ï¼šç¡®ä¿ `messages` æ ¼å¼æ­£ç¡®
- **Token ä¸Šé™**ï¼šå•æ¬¡è°ƒç”¨ä¸è¶…è¿‡ 32000 tokens
- **å¹¶å‘é™åˆ¶**ï¼šæœ€å¤š 10 ä¸ªå¹¶è¡Œä»»åŠ¡

## é«˜çº§ç”¨ä¾‹

### 1. å¤šè½®å¯¹è¯ä»£ç†

```python
def multi_turn_conversation(user_query):
    """å¤šè½®å¯¹è¯ç¤ºä¾‹"""

    # ç¬¬ä¸€è½®ï¼šåˆ†æç”¨æˆ·æ„å›¾
    intent_task = {
        "provider": "openai",
        "model": "gpt-3.5-turbo",
        "messages": [{
            "role": "user",
            "content": f"Analyze user intent: '{user_query}'"
        }]
    }

    intent_result = subagent_call(**intent_task)
    intent = intent_result["result"]

    # ç¬¬äºŒè½®ï¼šæ ¹æ®æ„å›¾ç”Ÿæˆå“åº”
    response_task = {
        "provider": "openai",
        "model": "gpt-4",
        "messages": [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": user_query},
            {"role": "assistant", "content": f"Detected intent: {intent}"},
            {"role": "user", "content": "Provide a detailed response."}
        ]
    }

    return subagent_call(**response_task)
```

### 2. æ–‡æ¡£åˆ†ææµæ°´çº¿

```python
def analyze_document(document_text):
    """å¹¶è¡Œåˆ†ææ–‡æ¡£çš„å¤šä¸ªç»´åº¦"""

    tasks = [
        {
            "name": "extract_entities",
            "provider": "openai",
            "model": "gpt-4",
            "messages": [{
                "role": "user",
                "content": f"Extract all named entities: {document_text}"
            }]
        },
        {
            "name": "summarize",
            "provider": "anthropic",
            "model": "claude-3-5-sonnet-20241022",
            "messages": [{
                "role": "user",
                "content": f"Summarize this document: {document_text}"
            }]
        },
        {
            "name": "key_points",
            "provider": "openai",
            "model": "gpt-3.5-turbo",
            "messages": [{
                "role": "user",
                "content": f"List key points: {document_text}"
            }]
        },
        {
            "name": "sentiment",
            "provider": "openai",
            "model": "gpt-3.5-turbo",
            "messages": [{
                "role": "user",
                "content": f"Analyze sentiment: {document_text}"
            }]
        }
    ]

    result = subagent_parallel(
        tasks=json.dumps(tasks),
        max_workers=4
    )

    return result
```

### 3. æ™ºèƒ½è·¯ç”±å†³ç­–

```python
def smart_routing(user_message):
    """æ ¹æ®æ¶ˆæ¯å¤æ‚åº¦é€‰æ‹©æ¨¡å‹"""

    # è¯„ä¼°æ¶ˆæ¯å¤æ‚åº¦
    condition_task = {
        "provider": "openai",
        "model": "gpt-3.5-turbo",
        "messages": [{
            "role": "user",
            "content": f"""Is this question complex and requires deep reasoning?
            Question: '{user_message}'
            Reply only 'true' or 'false'"""
        }],
        "temperature": 0.1
    }

    # å¤æ‚é—®é¢˜ç”¨ GPT-4
    complex_task = {
        "provider": "openai",
        "model": "gpt-4",
        "messages": [{"role": "user", "content": user_message}],
        "max_tokens": 2000
    }

    # ç®€å•é—®é¢˜ç”¨ GPT-3.5
    simple_task = {
        "provider": "openai",
        "model": "gpt-3.5-turbo",
        "messages": [{"role": "user", "content": user_message}],
        "max_tokens": 500
    }

    result = subagent_conditional(
        condition_task=json.dumps(condition_task),
        true_task=json.dumps(complex_task),
        false_task=json.dumps(simple_task)
    )

    return result
```

### 4. è‡ªæˆ‘éªŒè¯å’Œæ”¹è¿›

```python
def self_improving_generation(prompt):
    """ç”Ÿæˆ -> è¯„ä¼° -> æ”¹è¿›å¾ªç¯"""

    # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆåˆç¨¿
    draft_task = {
        "provider": "openai",
        "model": "gpt-4",
        "messages": [{"role": "user", "content": prompt}]
    }

    draft_result = subagent_call(**draft_task)
    draft = draft_result["result"]

    # ç¬¬äºŒæ­¥ï¼šè¯„ä¼°è´¨é‡
    eval_task = {
        "provider": "openai",
        "model": "gpt-4",
        "messages": [{
            "role": "user",
            "content": f"""Evaluate this response quality (1-10):
            Prompt: {prompt}
            Response: {draft}
            Reply with only a number."""
        }],
        "temperature": 0.1
    }

    eval_result = subagent_call(**eval_task)
    score = float(eval_result["result"].strip())

    # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœè´¨é‡ä¸å¤Ÿï¼Œè¦æ±‚æ”¹è¿›
    if score < 7:
        improve_task = {
            "provider": "openai",
            "model": "gpt-4",
            "messages": [{
                "role": "user",
                "content": f"""Improve this response:
                Original prompt: {prompt}
                Current response: {draft}
                Quality score: {score}/10
                Provide an improved version."""
            }]
        }

        return subagent_call(**improve_task)

    return draft_result
```

## æ•…éšœæ’æŸ¥

### æ£€æŸ¥æ—¥å¿—

MCP æœåŠ¡å™¨ä¼šè®°å½•è¯¦ç»†çš„è°ƒç”¨æ—¥å¿—åˆ° `mcp_server.log`ï¼š

```bash
tail -f mcp_server.log | grep -i subagent
```

æ—¥å¿—åŒ…å«ï¼š

- API è°ƒç”¨è¯¦æƒ…
- Token ä½¿ç”¨ç»Ÿè®¡
- é”™è¯¯ä¿¡æ¯
- é‡è¯•è®°å½•

### æµ‹è¯•è¿æ¥

ä½¿ç”¨ç®€å•çš„æµ‹è¯•è°ƒç”¨éªŒè¯é…ç½®ï¼š

```python
messages = [{"role": "user", "content": "Say 'Hello'"}]

# æµ‹è¯• OpenAI
result = subagent_call(
    provider="openai",
    model="gpt-3.5-turbo",
    messages=json.dumps(messages),
    max_tokens=10
)

# æµ‹è¯• Anthropic
result = subagent_call(
    provider="anthropic",
    model="claude-3-haiku-20240307",
    messages=json.dumps(messages),
    max_tokens=10
)
```

### éªŒè¯ API å¯†é’¥

```bash
# æµ‹è¯• OpenAI å¯†é’¥
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"

# æµ‹è¯• Anthropic å¯†é’¥
curl https://api.anthropic.com/v1/messages \
  -H "x-api-key: $ANTHROPIC_API_KEY" \
  -H "anthropic-version: 2023-06-01" \
  -H "content-type: application/json" \
  -d '{"model":"claude-3-haiku-20240307","messages":[{"role":"user","content":"Hi"}],"max_tokens":10}'
```

## æ€§èƒ½ä¼˜åŒ–

### 1. å¹¶å‘è°ƒä¼˜

```python
# æ ¹æ® API é€Ÿç‡é™åˆ¶è°ƒæ•´å¹¶å‘æ•°
# OpenAI Tier 1: max_workers=3
# OpenAI Tier 2+: max_workers=5-10
result = subagent_parallel(tasks=tasks, max_workers=3)
```

### 2. é™ä½æ¸©åº¦æé«˜é€Ÿåº¦

```python
# æ¸©åº¦è¶Šä½ï¼Œç”Ÿæˆè¶Šå¿«ï¼ˆä½†åˆ›é€ æ€§é™ä½ï¼‰
result = subagent_call(
    provider="openai",
    model="gpt-3.5-turbo",
    messages=messages,
    temperature=0.1  # æ›´ç¡®å®šçš„è¾“å‡º
)
```

### 3. ä½¿ç”¨æµå¼å“åº”ï¼ˆæœªæ¥åŠŸèƒ½ï¼‰

å½“å‰ç‰ˆæœ¬ä½¿ç”¨æ‰¹é‡å“åº”ã€‚æœªæ¥ç‰ˆæœ¬å°†æ”¯æŒæµå¼å“åº”ä»¥æå‡ç”¨æˆ·ä½“éªŒã€‚

## æœ€ä½³å®è·µ

1. **å§‹ç»ˆè®¾ç½® `max_tokens`**ï¼šé¿å…æ„å¤–çš„é•¿è¾“å‡º
2. **ä½¿ç”¨å¹¶è¡Œå¤„ç†**ï¼šç‹¬ç«‹ä»»åŠ¡åº”å¹¶è¡Œæ‰§è¡Œä»¥èŠ‚çœæ—¶é—´
3. **ç›‘æ§ Token ä½¿ç”¨**ï¼šå®šæœŸæ£€æŸ¥ `usage` å­—æ®µï¼Œé€šè¿‡ API provider æ§åˆ¶å°æŸ¥çœ‹æˆæœ¬
4. **é€‰æ‹©åˆé€‚çš„æ¨¡å‹**ï¼šç®€å•ä»»åŠ¡ç”¨ä¾¿å®œæ¨¡å‹ï¼Œå¤æ‚ä»»åŠ¡ç”¨é«˜çº§æ¨¡å‹
5. **ä¼˜é›…é™çº§**ï¼šæ£€æŸ¥ `status` å­—æ®µï¼Œå¤„ç†å¤±è´¥æƒ…å†µ
6. **ç¯å¢ƒå˜é‡ç®¡ç†**ï¼šä½¿ç”¨ `.env` æ–‡ä»¶æˆ–å¯†é’¥ç®¡ç†æœåŠ¡
7. **æ—¥å¿—å®¡æŸ¥**ï¼šå®šæœŸæ£€æŸ¥æ—¥å¿—ä»¥å‘ç°é—®é¢˜
8. **è‡ªå®šä¹‰æ¨¡å‹æ”¯æŒ**ï¼šå¯ä»¥ä½¿ç”¨ä»»æ„æ¨¡å‹åç§°ï¼ŒåŒ…æ‹¬è‡ªå®šä¹‰å¾®è°ƒæ¨¡å‹

## é™åˆ¶å’Œçº¦æŸ

- **å•æ¬¡è°ƒç”¨ token ä¸Šé™**ï¼š32000 tokens
- **å¹¶è¡Œä»»åŠ¡ä¸Šé™**ï¼š10 ä¸ª
- **æ— çŠ¶æ€**ï¼šä¸ç»´æŠ¤è·¨è°ƒç”¨çš„å¯¹è¯å†å²
- **æ— æµå¼è¾“å‡º**ï¼šä»…æ”¯æŒæ‰¹é‡å“åº”
- **API é€Ÿç‡é™åˆ¶**ï¼šå—å„ AI æä¾›å•†é™åˆ¶çº¦æŸ

## ç›¸å…³èµ„æº

- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs)
- [Anthropic API æ–‡æ¡£](https://docs.anthropic.com)
- [MCP åè®®è§„èŒƒ](https://modelcontextprotocol.io)
- [FastMCP æ¡†æ¶](https://github.com/jlowin/fastmcp)

## æ›´æ–°æ—¥å¿—

### v0.2.0 (2026-02-12)

- âœ… **ç§»é™¤è®¡è´¹åŠŸèƒ½**: ä¸å†è¿”å› `cost` å­—æ®µï¼Œç®€åŒ–ä»£ç ç»“æ„
- âœ… **è‡ªå®šä¹‰æ¨¡å‹æ”¯æŒ**: æ”¯æŒä½¿ç”¨ä»»æ„æ¨¡å‹åç§°ï¼Œæ— éœ€é¢„å…ˆé…ç½®ä»·æ ¼
- âœ… **ç§»é™¤ MODEL_PRICING**: ä¸å†ç»´æŠ¤ç¡¬ç¼–ç çš„ä»·æ ¼è¡¨
- âœ… **ç§»é™¤ CostCalculator**: åˆ é™¤æˆæœ¬è®¡ç®—é€»è¾‘
- âœ… **Token ç»Ÿè®¡ä¿ç•™**: ä»ç„¶è¿”å› `usage` å­—æ®µç”¨äºç›‘æ§
- ğŸ“ **æ–‡æ¡£æ›´æ–°**: æ›´æ–°ç¤ºä¾‹å’Œæœ€ä½³å®è·µ

âš ï¸ **ç ´åæ€§æ›´æ”¹**: è¿”å›å€¼ä¸å†åŒ…å« `cost` å­—æ®µ

### v0.1.0 (2026-02-11)

- âœ… åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- âœ… æ”¯æŒ OpenAI å’Œ Anthropic API
- âœ… å®ç° `subagent_call`, `subagent_parallel`, `subagent_conditional`
- âœ… Token ç»Ÿè®¡å’Œæˆæœ¬è¿½è¸ª
- âœ… è‡ªå®šä¹‰ API ç«¯ç‚¹æ”¯æŒ
- âœ… è‡ªåŠ¨é‡è¯•æœºåˆ¶
- âœ… å®Œæ•´çš„æµ‹è¯•è¦†ç›–

## åé¦ˆå’Œæ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤ Issue æˆ– Pull Requestã€‚

---

**Happy AI Orchestration! ğŸ¤–âœ¨**
